{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![My Image](data:image/png;base64,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)](https://arize.com)\n",
        "\n",
        "# Optimizing JSON Webpage Prompts with the Arize Prompt Learning SDK\n",
        "\n",
        "In this cookbook, we demonstrate a use case of the Arize Prompt Learning SDK by optimizing a system prompt for GPT-4o. The goal is to improve the model’s ability to generate accurate JSON representations of webpages in response to user queries. The dataset consists of prompts asking GPT to generate webpages, and we define 10 specific rules that the JSON outputs must satisfy. Using the SDK, we iteratively refine the prompt to achieve high accuracy on the training set, and then evaluate its performance on a separate test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        },
        "id": "cdQnCdhYogxi",
        "outputId": "87dc9c89-74b2-4a13-b372-96e40a3c3b11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting arize-phoenix-evals\n",
            "  Using cached arize_phoenix_evals-0.22.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting arize-phoenix-client\n",
            "  Using cached arize_phoenix_client-1.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting tiktoken\n",
            "  Using cached tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.96.1-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting arize-toolkit==1.0.5\n",
            "  Using cached arize_toolkit-1.0.5-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting scikit-learn\n",
            "  Using cached scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (31 kB)\n",
            "Collecting gql<4.0,>=3.0.0 (from arize-toolkit==1.0.5)\n",
            "  Using cached gql-3.5.3-py2.py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting pandas<3.0,>=0.25.3 (from arize-toolkit==1.0.5)\n",
            "  Using cached pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (91 kB)\n",
            "Collecting pydantic~=2.0 (from arize-toolkit==1.0.5)\n",
            "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
            "Collecting requests-toolbelt>=1.0.0 (from arize-toolkit==1.0.5)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting requests<3.0,>=2.28.1 (from arize-toolkit==1.0.5)\n",
            "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting graphql-core<3.2.7,>=3.2 (from gql<4.0,>=3.0.0->arize-toolkit==1.0.5)\n",
            "  Using cached graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting yarl<2.0,>=1.6 (from gql<4.0,>=3.0.0->arize-toolkit==1.0.5)\n",
            "  Using cached yarl-1.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (73 kB)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql<4.0,>=3.0.0->arize-toolkit==1.0.5)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting anyio<5,>=3.0 (from gql<4.0,>=3.0.0->arize-toolkit==1.0.5)\n",
            "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.0->gql<4.0,>=3.0.0->arize-toolkit==1.0.5)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sniffio>=1.1 (from anyio<5,>=3.0->gql<4.0,>=3.0.0->arize-toolkit==1.0.5)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /Users/priyanjindal/Prompt-Learning/.conda/lib/python3.11/site-packages (from anyio<5,>=3.0->gql<4.0,>=3.0.0->arize-toolkit==1.0.5) (4.14.1)\n",
            "Collecting numpy>=1.23.2 (from pandas<3.0,>=0.25.3->arize-toolkit==1.0.5)\n",
            "  Using cached numpy-2.3.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/priyanjindal/Prompt-Learning/.conda/lib/python3.11/site-packages (from pandas<3.0,>=0.25.3->arize-toolkit==1.0.5) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas<3.0,>=0.25.3->arize-toolkit==1.0.5)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<3.0,>=0.25.3->arize-toolkit==1.0.5)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic~=2.0->arize-toolkit==1.0.5)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.33.2 (from pydantic~=2.0->arize-toolkit==1.0.5)\n",
            "  Using cached pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting typing-inspection>=0.4.0 (from pydantic~=2.0->arize-toolkit==1.0.5)\n",
            "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3.0,>=2.28.1->arize-toolkit==1.0.5)\n",
            "  Using cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3.0,>=2.28.1->arize-toolkit==1.0.5)\n",
            "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3.0,>=2.28.1->arize-toolkit==1.0.5)\n",
            "  Using cached certifi-2025.7.14-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting multidict>=4.0 (from yarl<2.0,>=1.6->gql<4.0,>=3.0.0->arize-toolkit==1.0.5)\n",
            "  Using cached multidict-6.6.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.1 (from yarl<2.0,>=1.6->gql<4.0,>=3.0.0->arize-toolkit==1.0.5)\n",
            "  Using cached propcache-0.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
            "Collecting tqdm (from arize-phoenix-evals)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting httpx (from arize-phoenix-client)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting regex>=2022.1.18 (from tiktoken)\n",
            "  Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Using cached jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
            "Collecting httpcore==1.* (from httpx->arize-phoenix-client)\n",
            "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx->arize-phoenix-client)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting scipy>=1.8.0 (from scikit-learn)\n",
            "  Using cached scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/priyanjindal/Prompt-Learning/.conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=0.25.3->arize-toolkit==1.0.5) (1.17.0)\n",
            "Using cached arize_toolkit-1.0.5-py3-none-any.whl (68 kB)\n",
            "Using cached gql-3.5.3-py2.py3-none-any.whl (74 kB)\n",
            "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "Using cached pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
            "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
            "Using cached pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
            "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl (198 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Using cached yarl-1.20.1-cp311-cp311-macosx_11_0_arm64.whl (89 kB)\n",
            "Using cached arize_phoenix_evals-0.22.0-py3-none-any.whl (64 kB)\n",
            "Using cached arize_phoenix_client-1.12.0-py3-none-any.whl (65 kB)\n",
            "Using cached tiktoken-0.9.0-cp311-cp311-macosx_11_0_arm64.whl (1.0 MB)\n",
            "Downloading openai-1.96.1-py3-none-any.whl (757 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.5/757.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Using cached jiter-0.10.0-cp311-cp311-macosx_11_0_arm64.whl (321 kB)\n",
            "Using cached scikit_learn-1.7.0-cp311-cp311-macosx_12_0_arm64.whl (10.7 MB)\n",
            "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Using cached certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Using cached multidict-6.6.3-cp311-cp311-macosx_11_0_arm64.whl (44 kB)\n",
            "Using cached numpy-2.3.1-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
            "Using cached propcache-0.3.2-cp311-cp311-macosx_11_0_arm64.whl (43 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached scipy-1.16.0-cp311-cp311-macosx_14_0_arm64.whl (20.8 MB)\n",
            "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, urllib3, tzdata, typing-inspection, tqdm, threadpoolctl, sniffio, regex, pydantic-core, propcache, numpy, multidict, joblib, jiter, idna, h11, graphql-core, distro, charset_normalizer, certifi, backoff, annotated-types, yarl, scipy, requests, pydantic, pandas, httpcore, anyio, tiktoken, scikit-learn, requests-toolbelt, httpx, gql, arize-phoenix-evals, openai, arize-toolkit, arize-phoenix-client\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38/38\u001b[0m [arize-phoenix-client]ze-toolkit]izer]\n",
            "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.9.0 arize-phoenix-client-1.12.0 arize-phoenix-evals-0.22.0 arize-toolkit-1.0.5 backoff-2.2.1 certifi-2025.7.14 charset_normalizer-3.4.2 distro-1.9.0 gql-3.5.3 graphql-core-3.2.6 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 jiter-0.10.0 joblib-1.5.1 multidict-6.6.3 numpy-2.3.1 openai-1.96.1 pandas-2.3.1 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 pytz-2025.2 regex-2024.11.6 requests-2.32.4 requests-toolbelt-1.0.0 scikit-learn-1.7.0 scipy-1.16.0 sniffio-1.3.1 threadpoolctl-3.6.0 tiktoken-0.9.0 tqdm-4.67.1 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 yarl-1.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install arize-phoenix-evals arize-phoenix-client tiktoken openai arize-toolkit==1.0.5 scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "NUM_SAMPLES: Controls how many rows to sample from the full dataset. Set to 0 to use all available data, or a positive number to limit the sample size for faster experimentation.\n",
        "\n",
        "TRAIN_SPLIT_FRACTION: Determines the train/test split ratio. 0.8 means 80% of data goes to training set, 20% to test set.\n",
        "\n",
        "NUM_RULES: Specifies the number of rules to use for evaluation. This determines which prompt files to load (e.g., evaluator-prompt-10.txt vs evaluator-prompt-50.txt).\n",
        "\n",
        "NUM_OPTIMIZATION_LOOPS: Sets how many optimization iterations to run per experiment. Each loop generates outputs, evaluates them, and refines the prompt.\n",
        "\n",
        "These variables control the experiment scope, data splitting, evaluation criteria, and optimization intensity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CONFIG: Number of samples to use for the experiment. Adjust as needed.\n",
        "NUM_SAMPLES = 100  # Number of rows to sample from the full dataset, 0 for all\n",
        "TRAIN_SPLIT_FRACTION = 0.5  # Fraction of data to use for training (rest for testing)\n",
        "NUM_RULES = 50  # Number of rules in the prompt - adjust based on your evaluator prompt (this is NOT working on Config)\n",
        "NUM_OPTIMIZATION_LOOPS = 2  # Number of optimization loops per experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the following cell. It simply monkey patches one of our Phoenix methods for this notebook to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/priyanjindal/Prompt-Learning/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio, re\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# 1️⃣  stricter variable detector\n",
        "from phoenix.evals.templates import PromptTemplate, PromptPartTemplate\n",
        "_TEMPLATE_RE = re.compile(r\"\\{([a-zA-Z_][a-zA-Z0-9_]*)\\}\")\n",
        "def _parse_variables_strict(self, tmpl: list[PromptPartTemplate]):  # [...]\n",
        "    vars = set()\n",
        "    for p in tmpl:\n",
        "        vars.update(m.group(1) for m in _TEMPLATE_RE.finditer(p.template))\n",
        "    return list(vars)\n",
        "PromptTemplate._parse_variables = _parse_variables_strict\n",
        "\n",
        "# 2️⃣  literal‑brace formatter\n",
        "from phoenix.evals.templates import PromptPart, MultimodalPrompt\n",
        "def _format_literal(self, variable_values, options=None):  # [...]\n",
        "    prompt_msgs = []\n",
        "    for part in self.prompt(options):\n",
        "        msg = part.template\n",
        "        for var in self.variables:\n",
        "            msg = msg.replace(f\"{{{var}}}\", str(variable_values[var]))\n",
        "        prompt_msgs.append(PromptPart(content_type=part.content_type, content=msg))\n",
        "    return MultimodalPrompt(parts=prompt_msgs)\n",
        "PromptTemplate.format = _format_literal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## OpenAI Key\n",
        "We will be using OpenAI to generate the webpage jsons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li84EDzhqSMj",
        "outputId": "e7c054bd-de4e-48bd-da2c-a1db214ac130"
      },
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
        "client = openai.Client(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Test Datasets\n",
        "\n",
        "Create training and test datasets, and export to Arize. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fbekkrdcopWx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset_1000 = pd.read_csv(\"https://storage.googleapis.com/arize-assets/dev-rel/prompt-learning/queries.csv\")\n",
        "dataset_sample = dataset_1000.sample(NUM_SAMPLES) # 100 rows\n",
        "\n",
        "# 80-20 split\n",
        "train_set = dataset_sample.sample(frac=TRAIN_SPLIT_FRACTION, random_state=42)\n",
        "test_set = dataset_sample.drop(train_set.index)\n",
        "\n",
        "train_set.to_csv(\"train.csv\", index=False)\n",
        "test_set.to_csv(\"test.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial System Prompt\n",
        "\n",
        "Initialize your system prompt. This is the original prompt that will be tested and optimized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zcK2y2OYqn6Q"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"You are an expert in JSON webpage creation. This is your task: {input}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluators\n",
        "\n",
        "This cell initializes two evaluators that use LLMs as judges to assess the quality of generated outputs.\n",
        "\n",
        "**`evaluate_output`**: A comprehensive evaluator that assesses JSON webpage correctness against the input query and evaluation rules. It provides:\n",
        "- **Correctness labels**: \"correct\" or \"incorrect\" \n",
        "- **Detailed explanations**: Reasoning for the evaluation decision\n",
        "\n",
        "**`rule_checker`**: A specialized evaluator that performs granular rule-by-rule analysis. It:\n",
        "- **Checks individual rules**: Examines each rule compliance separately\n",
        "\n",
        "Both evaluators generate feedback that the optimization loop uses to iteratively improve the system prompt. The explanations and rule violations guide the MetaPromptOptimizer in creating more effective prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZpcWWF8qrIz4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "from phoenix.evals import OpenAIModel, llm_generate\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "def find_correctness(output):\n",
        "    \"\"\"Extract correctness from LLM output\"\"\"\n",
        "    # Look for \"correct\" or \"incorrect\" in the response\n",
        "    pattern = r'\"correctness\":\\s*\"?(correct|incorrect)\"?'\n",
        "    match = re.search(pattern, output, re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1).lower()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def find_explanation(output):\n",
        "    \"\"\"Extract explanation from LLM output\"\"\"\n",
        "    # Look for explanation field in JSON\n",
        "    pattern = r'\"explanation\":\\s*\"([^\"]*)\"'\n",
        "    match = re.search(pattern, output, re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def evaluate_output_parser(response: str, row_index: int) -> dict:\n",
        "    \"\"\"Parser function for evaluate_output evaluator\"\"\"\n",
        "    correctness = find_correctness(response)\n",
        "    explanation = find_explanation(response)\n",
        "    \n",
        "    return {\n",
        "        \"correctness\": correctness,\n",
        "        \"explanation\": explanation\n",
        "    }\n",
        "\n",
        "def rule_checker_parser(response: str, row_index: int) -> dict:\n",
        "    \"\"\"Parser function for rule_checker evaluator\"\"\"\n",
        "    explanation = find_explanation(response)\n",
        "    \n",
        "    return {\n",
        "        \"rule_violations\": explanation\n",
        "    }\n",
        "\n",
        "def evaluate_output(dataset):\n",
        "    \"\"\"Evaluator that checks JSON web page correctness using llm_generate\"\"\"\n",
        "    \n",
        "    # Create the evaluation template\n",
        "    \n",
        "    with open(f\"../prompts/evaluator-prompt-{NUM_RULES}.txt\", \"r\") as file:\n",
        "        evaluation_template = file.read()\n",
        "\n",
        "    # Create the model\n",
        "    eval_model = OpenAIModel(\n",
        "        model=\"gpt-4.1-2025-04-14\",\n",
        "        model_kwargs={\n",
        "            \"response_format\": {\"type\": \"json_object\"},\n",
        "            \"temperature\": 0\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Generate evaluations using llm_generate\n",
        "    evaluation_results = llm_generate(\n",
        "        dataframe=dataset,\n",
        "        template=evaluation_template,\n",
        "        model=eval_model,\n",
        "        output_parser=evaluate_output_parser,\n",
        "        concurrency=40,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Merge the results back into the original dataset\n",
        "    dataset = dataset.copy()\n",
        "    for col in [\"correctness\", \"explanation\"]:\n",
        "        if col in evaluation_results.columns:\n",
        "            dataset[col] = evaluation_results[col]\n",
        "\n",
        "    return dataset, [\"correctness\", \"explanation\"]\n",
        "\n",
        "def rule_checker(dataset):\n",
        "    \"\"\"Evaluator that checks which rules are broken using llm_generate\"\"\"\n",
        "    \n",
        "    # Create the rule checking template\n",
        "    with open(f\"../prompts/rule-checker-prompt-{NUM_RULES}.txt\", \"r\") as file:\n",
        "        rule_check_template = file.read()\n",
        "\n",
        "    # Create the model\n",
        "    eval_model = OpenAIModel(\n",
        "        model_name=\"gpt-4.1-2025-04-14\",\n",
        "        model_kwargs={\n",
        "            \"response_format\": {\"type\": \"json_object\"},\n",
        "            \"temperature\": 0\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Generate rule checks using llm_generate\n",
        "    rule_check_results = llm_generate(\n",
        "        dataframe=dataset,\n",
        "        template=rule_check_template,\n",
        "        model=eval_model,\n",
        "        output_parser=rule_checker_parser,\n",
        "        concurrency=40,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Merge the results back into the original dataset\n",
        "    dataset = dataset.copy()\n",
        "    if \"rule_violations\" in rule_check_results.columns:\n",
        "        dataset[\"rule_violations\"] = rule_check_results[\"rule_violations\"]\n",
        "\n",
        "    return dataset, [\"rule_violations\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output Generation\n",
        "\n",
        "This cell defines the function that generates JSON webpage outputs using the current system prompt.\n",
        "\n",
        "**Model**: Uses GPT-4.1 with JSON response format and zero temperature for consistent outputs.\n",
        "\n",
        "**Function**: Takes a dataset and system prompt, generates outputs for all rows, and returns the results for evaluation.\n",
        "\n",
        "**Usage**: Called during each optimization iteration to produce outputs that will be evaluated by the assessors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_output(dataset, system_prompt):\n",
        "    output_model = OpenAIModel(\n",
        "        model=\"gpt-4.1-2025-04-14\",\n",
        "        model_kwargs={\n",
        "            \"response_format\": {\"type\": \"json_object\"},\n",
        "            \"temperature\": 0\n",
        "        }\n",
        "    )\n",
        "    outputs = llm_generate(\n",
        "        dataframe=dataset,\n",
        "        template=system_prompt,\n",
        "        model=output_model,\n",
        "        concurrency=40,\n",
        "        verbose=True\n",
        "    )\n",
        "    return outputs[\"output\"]\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Additional Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "def compute_metric(y_true, y_pred, scorer=\"accuracy\"):\n",
        "    \"\"\"\n",
        "    Compute the requested metric for binary classification.\n",
        "    y_true and y_pred should be lists or arrays of \"correct\"/\"incorrect\" labels.\n",
        "    scorer: one of \"accuracy\", \"f1\", \"precision\", \"recall\"\n",
        "    \"\"\"\n",
        "    # Map to binary\n",
        "    y_true_bin = [1 if y == \"correct\" else 0 for y in y_true]\n",
        "    y_pred_bin = [1 if y == \"correct\" else 0 for y in y_pred]\n",
        "    if scorer == \"accuracy\":\n",
        "        return accuracy_score(y_true_bin, y_pred_bin)\n",
        "    elif scorer == \"f1\":\n",
        "        return f1_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "    elif scorer == \"precision\":\n",
        "        return precision_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "    elif scorer == \"recall\":\n",
        "        return recall_score(y_true_bin, y_pred_bin, zero_division=0)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown scorer: {scorer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimization Loop\n",
        "\n",
        "This cell implements the core prompt optimization algorithm. The loop follows a 3-step process:\n",
        "\n",
        "**Generate & Evaluate**: Generate outputs using the current prompt on the test dataset and evaluate their correctness  \n",
        "**Train & Optimize**: If results are unsatisfactory, generate outputs on the training set, evaluate them, and use the feedback to create an improved prompt  \n",
        "**Iterate**: Repeat until either the threshold is met or all loops are completed\n",
        "\n",
        "The algorithm tracks metrics across iterations and returns detailed results including train/test accuracy scores, optimized prompts, and raw evaluation data. The optimization uses the MetaPromptOptimizer to iteratively refine the system prompt based on evaluator feedback.\n",
        "\n",
        "**Key parameters:**\n",
        "- `threshold`: Target accuracy score to stop optimization\n",
        "- `loops`: Maximum number of optimization iterations  \n",
        "- `scorer`: Metric to optimize (accuracy, f1, precision, recall)\n",
        "- `num_rules`: Number of evaluation rules to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from arize_toolkit.extensions.prompt_optimizer import MetaPromptOptimizer\n",
        "\n",
        "def optimize_loop(\n",
        "    train_set,\n",
        "    test_set,\n",
        "    system_prompt,\n",
        "    evaluators,\n",
        "    threshold=0.7,\n",
        "    loops=5,\n",
        "    scorer=\"accuracy\",\n",
        "):\n",
        "    \"\"\"\n",
        "    scorer: one of \"accuracy\", \"f1\", \"precision\", \"recall\"\n",
        "    threshold: float, threshold for the selected metric\n",
        "\n",
        "    Returns:\n",
        "        dict with keys:\n",
        "            \"train\": list of train set scores per run\n",
        "            \"test\": list of test set scores per run\n",
        "            \"prompt\": list of system prompts used for each test run\n",
        "            \"raw\": list of test set DataFrames (deepcopy) for each test run\n",
        "    \"\"\"\n",
        "    import copy\n",
        "\n",
        "    curr_loop = 1\n",
        "    train_metrics = []\n",
        "    test_metrics = []\n",
        "    prompts = []\n",
        "    raw_dfs = []\n",
        "\n",
        "    print(f\"🚀 Starting prompt optimization with {loops} iterations (scorer: {scorer}, threshold: {threshold})\")\n",
        "    print()\n",
        "    \n",
        "    # Initial test evaluation before optimization\n",
        "    print(f\"📊 Initial evaluation:\")\n",
        "    test_set[\"output\"] = generate_output(test_set, system_prompt)\n",
        "    \n",
        "    test_evals_all = evaluate_output(test_set)[0]\n",
        "    test_evals = test_evals_all[\"correctness\"]\n",
        "    y_true = [\"correct\"] * len(test_evals)\n",
        "    y_pred = test_evals\n",
        "    initial_metric_value = compute_metric(y_true, y_pred, scorer=scorer)\n",
        "    test_metrics.append(initial_metric_value)\n",
        "    prompts.append(system_prompt)\n",
        "    raw_dfs.append(copy.deepcopy(test_set))\n",
        "    \n",
        "    print(f\"✅ Initial test {scorer}: {initial_metric_value}\")\n",
        "    print('\\n')\n",
        "    \n",
        "    if initial_metric_value >= threshold:\n",
        "        print(f\"🎉 Initial prompt already meets threshold!\")\n",
        "        result = {\n",
        "            \"train\": train_metrics,\n",
        "            \"test\": test_metrics,\n",
        "            \"prompt\": prompts,\n",
        "            \"raw\": raw_dfs,\n",
        "        }\n",
        "        return result\n",
        "    \n",
        "    while loops > 0:\n",
        "        print(f\"📊 Loop {curr_loop}: Optimizing prompt...\")\n",
        "        \n",
        "        # 1. Train set evaluation and optimization\n",
        "        train_outputs = generate_output(train_set, system_prompt)\n",
        "        train_set[\"output\"] = train_outputs\n",
        "\n",
        "        train_set[\"correctness\"] = [None] * len(train_set)\n",
        "        train_set[\"explanation\"] = [None] * len(train_set)\n",
        "        train_set[\"rule_violations\"] = [None] * len(train_set)\n",
        "\n",
        "        optimizer = MetaPromptOptimizer(\n",
        "            prompt=system_prompt,\n",
        "            model_choice=\"gpt-4o\",\n",
        "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        "        )\n",
        "        \n",
        "        train_set, _ = optimizer.run_evaluators(\n",
        "            train_set,\n",
        "            evaluators,\n",
        "            feedback_columns=[\"correctness\", \"explanation\", \"rule_violations\"]\n",
        "        )\n",
        "\n",
        "        system_prompt = optimizer.optimize(\n",
        "            train_set,\n",
        "            \"output\",\n",
        "            feedback_columns=[\"correctness\", \"explanation\", \"rule_violations\"],\n",
        "            context_size_k=128000\n",
        "        )\n",
        "\n",
        "        # Evaluate train set after optimization\n",
        "        train_outputs_post = generate_output(train_set, system_prompt)\n",
        "        train_set_post = train_set.copy()\n",
        "        train_set_post[\"output\"] = train_outputs_post\n",
        "        train_evals_post_all = evaluate_output(train_set_post)[0]\n",
        "        train_evals_post = train_evals_post_all[\"correctness\"]\n",
        "        y_true_train_post = [\"correct\"] * len(train_evals_post)\n",
        "        y_pred_train_post = train_evals_post\n",
        "        train_metric_post_value = compute_metric(y_true_train_post, y_pred_train_post, scorer=scorer)\n",
        "        train_metrics.append(train_metric_post_value)\n",
        "        print(f\"✅ Train {scorer}: {train_metric_post_value}\")\n",
        "\n",
        "        # 2. Test set evaluation with optimized prompt\n",
        "        test_set[\"output\"] = generate_output(test_set, system_prompt)\n",
        "        \n",
        "        test_evals_all = evaluate_output(test_set)[0]\n",
        "        test_evals = test_evals_all[\"correctness\"]\n",
        "        y_true = [\"correct\"] * len(test_evals)\n",
        "        y_pred = test_evals\n",
        "        metric_value = compute_metric(y_true, y_pred, scorer=scorer)\n",
        "        test_metrics.append(metric_value)\n",
        "        prompts.append(system_prompt)\n",
        "        raw_dfs.append(copy.deepcopy(test_set))\n",
        "        \n",
        "        print(f\"✅ Test {scorer}: {metric_value}\")\n",
        "        print(\"\\n\")\n",
        "        \n",
        "        # 3. Check threshold\n",
        "        if metric_value >= threshold:\n",
        "            print(f\"🎉 Threshold reached! Stopping optimization.\")\n",
        "            result = {\n",
        "                \"train\": train_metrics,\n",
        "                \"test\": test_metrics,\n",
        "                \"prompt\": prompts,\n",
        "                \"raw\": raw_dfs,\n",
        "            }\n",
        "            return result\n",
        "\n",
        "        loops -= 1\n",
        "        curr_loop += 1\n",
        "\n",
        "    print(f\"🔄 All {curr_loop-1} optimization loops completed.\")\n",
        "    result = {\n",
        "        \"train\": train_metrics,\n",
        "        \"test\": test_metrics,\n",
        "        \"prompt\": prompts,\n",
        "        \"raw\": raw_dfs,\n",
        "    }\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Saving Functions\n",
        "\n",
        "This cell defines two utility functions for saving experiment results in different formats:\n",
        "\n",
        "**`save_experiment_results()`**: Saves complete experiment data to JSON format with timestamps. Useful for preserving all experiment details including raw evaluation data and metadata.\n",
        "\n",
        "**`save_single_experiment_csv()`**: Creates lightweight CSV files with iteration-level data including:\n",
        "- Iteration number\n",
        "- Number of rules used\n",
        "- Test and train accuracy scores  \n",
        "- Optimized prompt text\n",
        "\n",
        "The CSV format makes it easy to analyze performance trends and prompt evolution over time. Files are automatically timestamped to avoid overwriting previous results.\n",
        "\n",
        "**Output format**: Each row represents one optimization iteration with metrics and the corresponding optimized prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def save_experiment_results(results, filename=\"experiment_results.json\"):\n",
        "    \"\"\"Save experiment results to a JSON file.\"\"\"\n",
        "    \n",
        "    # Add timestamp to results\n",
        "    results_with_timestamp = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"results\": results\n",
        "    }\n",
        "    \n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(results_with_timestamp, f, indent=2, default=str)\n",
        "    \n",
        "    print(f\"✅ Results saved to {filename}\")\n",
        "\n",
        "def save_single_experiment_csv(results, filename):\n",
        "    \"\"\"\n",
        "    Save a single experiment's results to CSV format.\n",
        "    \n",
        "    Args:\n",
        "        results: Results from a single optimize_loop run\n",
        "        filename: Output CSV filename\n",
        "    \"\"\"\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    # Extract data\n",
        "    train_metrics = results.get('train', [])\n",
        "    test_metrics = results['test']\n",
        "    prompts = results['prompt']\n",
        "    \n",
        "    # Create DataFrame\n",
        "    data = []\n",
        "    for i, (test_metric, prompt) in enumerate(zip(test_metrics, prompts)):\n",
        "        row = {\n",
        "            'iteration': i,\n",
        "            'test_accuracy': test_metric,\n",
        "            'prompt': prompt\n",
        "        }\n",
        "        \n",
        "        # Add train metric if available\n",
        "        if i < len(train_metrics):\n",
        "            row['train_accuracy'] = train_metrics[i]\n",
        "        \n",
        "        data.append(row)\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Save to CSV with timestamp\n",
        "    filename_with_timestamp = f\"{filename}_{timestamp}.csv\"\n",
        "    df.to_csv(filename_with_timestamp, index=False)\n",
        "    print(f\"✅ Results saved to {filename_with_timestamp}\")\n",
        "    print(f\"   📊 {len(df)} iterations\")\n",
        "    print(f\"   📈 Final accuracy: {df['test_accuracy'].iloc[-1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment Execution\n",
        "\n",
        "This cell runs a prompt optimization experiment and saves the results.\n",
        "\n",
        "**Execution**: Runs the optimization loop with the specified evaluators and configuration parameters, tracking performance across iterations.\n",
        "\n",
        "**Results Saving**: \n",
        "- **JSON format**: Saves complete experiment data with timestamps for detailed analysis\n",
        "- **CSV format**: Creates lightweight CSV files with iteration data, metrics, and prompts for easy visualization\n",
        "\n",
        "The CSV output includes columns for iteration number, number of rules, test/train accuracy scores, and the optimized prompt text, making it easy to analyze performance trends and prompt evolution over time.\n",
        "\n",
        "**Output files**: \n",
        "- `experiment_results.json` - Complete experiment data\n",
        "- `experiment_YYYYMMDD_HHMMSS.csv` - Timestamped CSV with iteration metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Starting prompt optimization with 2 iterations (scorer: accuracy, threshold: 0.7)\n",
            "\n",
            "📊 Initial evaluation:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:30<00:00 |  1.24s/it\n",
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:10<00:00 |  2.31it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Initial test accuracy: 0.0\n",
            "\n",
            "\n",
            "📊 Loop 1: Optimizing prompt...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:30<00:00 |  1.23s/it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Running 2 evaluator(s)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:08<00:00 |  2.86it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Evaluator 1: explanation\n",
            "The `model_name` field is deprecated. Use `model` instead.                 This will be removed in a future release.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:07<00:00 |  3.21it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Evaluator 2: rule_violations\n",
            "\n",
            "🔧 Creating batches with 128,000 token limit\n",
            "📊 Processing 25 examples in 1 batches\n",
            "   ✅ Batch 1/1: Optimized\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:27<00:00 |  1.11s/it\n",
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:11<00:00 |  2.14it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Train accuracy: 0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:18<00:00 |  1.36it/s\n",
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:07<00:00 |  3.17it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Test accuracy: 0.16\n",
            "\n",
            "\n",
            "📊 Loop 2: Optimizing prompt...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:22<00:00 |  1.13it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 Running 2 evaluator(s)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:08<00:00 |  2.98it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Evaluator 1: explanation\n",
            "The `model_name` field is deprecated. Use `model` instead.                 This will be removed in a future release.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:07<00:00 |  3.45it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   ✅ Evaluator 2: rule_violations\n",
            "\n",
            "🔧 Creating batches with 128,000 token limit\n",
            "📊 Processing 25 examples in 1 batches\n",
            "   ✅ Batch 1/1: Optimized\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:19<00:00 |  1.31it/s\n",
            "llm_generate |██████████| 25/25 (100.0%) | ⏳ 00:10<00:00 |  2.27it/s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Train accuracy: 0.32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llm_generate |█████████▏| 23/25 (92.0%) | ⏳ 00:13<00:00 |  3.06it/s"
          ]
        }
      ],
      "source": [
        "evaluators = [evaluate_output, rule_checker]\n",
        "results = optimize_loop(\n",
        "    train_set, test_set, system_prompt, evaluators,\n",
        "    loops=NUM_OPTIMIZATION_LOOPS\n",
        ")\n",
        "\n",
        "# Save results\n",
        "save_experiment_results(results, \"experiment_results.json\")\n",
        "\n",
        "# Save CSV results\n",
        "save_single_experiment_csv(results, \"experiment\")\n",
        "\n",
        "print(\"\\n📊 Experiment results:\")\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Now you have your optimized system prompt!\n",
        "\n",
        "Here is the prompt that achieved the best test accuracy across the optimization iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_best_prompt(results):\n",
        "    \"\"\"\n",
        "    Extract the prompt that achieved the best test accuracy.\n",
        "    \n",
        "    Args:\n",
        "        results: Results from optimize_loop or experiment\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (best_prompt, best_accuracy, iteration_number)\n",
        "    \"\"\"\n",
        "    test_metrics = results['test']\n",
        "    prompts = results['prompt']\n",
        "    \n",
        "    # Find the iteration with highest test accuracy\n",
        "    best_iteration = test_metrics.index(max(test_metrics))\n",
        "    best_accuracy = test_metrics[best_iteration]\n",
        "    best_prompt = prompts[best_iteration]\n",
        "    \n",
        "    return best_prompt, best_accuracy, best_iteration\n",
        "\n",
        "# Usage example:\n",
        "best_prompt, best_accuracy, best_iter = get_best_prompt(results)\n",
        "print(f\"Best prompt (iteration {best_iter}, accuracy: {best_accuracy:.3f}):\")\n",
        "print(best_prompt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "073586a404aa411f945be3d54b595e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e61bdfd21dae451cb68035cb634d5c4c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97f8cea796734f67bea6ad313a99ca65",
            "value": 1
          }
        },
        "077dfc5bede54795911de8a64d24c9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebe17886b72b459a992bbc71ee851605",
              "IPY_MODEL_eefdf7147f2c4d3b942e9294d23fd597",
              "IPY_MODEL_550c49fda9ec42ca9dc3b7e742359032"
            ],
            "layout": "IPY_MODEL_08166a71b33d4d8cb7084d213cf72299"
          }
        },
        "07ed502f8ff04849b0608800cc5c49d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08166a71b33d4d8cb7084d213cf72299": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b46a43169a0463f971d5fb921b4558b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f4203e88b2e44b3bf93271d73a56109": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21672a011061442ebdbae4dfa3dbeba1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2793d82a505d412f90f8640440054806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21672a011061442ebdbae4dfa3dbeba1",
            "placeholder": "​",
            "style": "IPY_MODEL_5a38b40c72044ca0a27791d0e71bbf42",
            "value": "running tasks "
          }
        },
        "2d72ff2fcf084ac4838543c44c42d9fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7353cf632b483282ea1185ea68c9db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f48810972884daeb1374531191e0df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2793d82a505d412f90f8640440054806",
              "IPY_MODEL_073586a404aa411f945be3d54b595e11",
              "IPY_MODEL_9ac825bd3c784f2c9160c689411238af"
            ],
            "layout": "IPY_MODEL_07ed502f8ff04849b0608800cc5c49d6"
          }
        },
        "3262940173b14a4baa108d7e5add40f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d72ff2fcf084ac4838543c44c42d9fb",
            "placeholder": "​",
            "style": "IPY_MODEL_ea7d35bba0d24f8490d684e699fae4b3",
            "value": "running experiment evaluations "
          }
        },
        "3dc1da70daf1451da3bb50d9fc8349a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f0f1bccdc364a798b5b85ca344299c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4481b37f990f448d8f505df42493ffd1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d98c878ad0d46548db1d7d67559259d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550c49fda9ec42ca9dc3b7e742359032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f0f1bccdc364a798b5b85ca344299c3",
            "placeholder": "​",
            "style": "IPY_MODEL_3dc1da70daf1451da3bb50d9fc8349a7",
            "value": " 1/1 (100.0%) | ⏳ 00:54&lt;00:00 |  1.88s/it"
          }
        },
        "5a38b40c72044ca0a27791d0e71bbf42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ea7801af656414482f2560f7f3f5f87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ecab28ceb3049b6b229308b6b73b0f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe62be50c36d43b79eab0a71aa90eabe",
              "IPY_MODEL_c4f2ae5cdcf24c00a87470694054aff4",
              "IPY_MODEL_bc08bc6b1e704387a8ed1f0e8b4a07dd"
            ],
            "layout": "IPY_MODEL_9aa36db349534821a8dcabbfd07b9db3"
          }
        },
        "628714be224349ba94db32f964899f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c95addc56ee4c1e942654b1b2380fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "876bc03165a745c5b6304e0b848b8b24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "882804f22c494765890121de37d02cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90271946bbd9492a823dea69080b74e9",
            "placeholder": "​",
            "style": "IPY_MODEL_945510347562487d897195f6d6a063bf",
            "value": " 1/1 (100.0%) | ⏳ 01:06&lt;00:00 |  2.08s/it"
          }
        },
        "90271946bbd9492a823dea69080b74e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "905e5b3d7c4b40b3bd8f65f26b5123ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876bc03165a745c5b6304e0b848b8b24",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b707d5753fa044e9988151871ee90526",
            "value": 1
          }
        },
        "945510347562487d897195f6d6a063bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97f8cea796734f67bea6ad313a99ca65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97fc63828355408a96a00c129adbf5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa36db349534821a8dcabbfd07b9db3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac825bd3c784f2c9160c689411238af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea7801af656414482f2560f7f3f5f87",
            "placeholder": "​",
            "style": "IPY_MODEL_6c95addc56ee4c1e942654b1b2380fcf",
            "value": " 1/1 (100.0%) | ⏳ 01:18&lt;00:00 | 11.68s/it"
          }
        },
        "b707d5753fa044e9988151871ee90526": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc08bc6b1e704387a8ed1f0e8b4a07dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be77fc22c61141288a8bde24ba498251",
            "placeholder": "​",
            "style": "IPY_MODEL_1f4203e88b2e44b3bf93271d73a56109",
            "value": " 1/1 (100.0%) | ⏳ 01:04&lt;00:00 |  9.65s/it"
          }
        },
        "be77fc22c61141288a8bde24ba498251": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b8327e1bb94c0ea35a3906fcaeda42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4f2ae5cdcf24c00a87470694054aff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4481b37f990f448d8f505df42493ffd1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b46a43169a0463f971d5fb921b4558b",
            "value": 1
          }
        },
        "c9de3a9ad99f491c883ce8ef570fc556": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca00f064927f4e8398a59b34c7ea8827": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df75b6e02161454ebdc881d9269f44c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3262940173b14a4baa108d7e5add40f5",
              "IPY_MODEL_905e5b3d7c4b40b3bd8f65f26b5123ec",
              "IPY_MODEL_882804f22c494765890121de37d02cc6"
            ],
            "layout": "IPY_MODEL_4d98c878ad0d46548db1d7d67559259d"
          }
        },
        "e61bdfd21dae451cb68035cb634d5c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7d35bba0d24f8490d684e699fae4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebe17886b72b459a992bbc71ee851605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97fc63828355408a96a00c129adbf5f2",
            "placeholder": "​",
            "style": "IPY_MODEL_2e7353cf632b483282ea1185ea68c9db",
            "value": "running experiment evaluations "
          }
        },
        "eefdf7147f2c4d3b942e9294d23fd597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9de3a9ad99f491c883ce8ef570fc556",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_628714be224349ba94db32f964899f3e",
            "value": 1
          }
        },
        "fe62be50c36d43b79eab0a71aa90eabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca00f064927f4e8398a59b34c7ea8827",
            "placeholder": "​",
            "style": "IPY_MODEL_c4b8327e1bb94c0ea35a3906fcaeda42",
            "value": "running tasks "
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
